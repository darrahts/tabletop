{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Decision Process Example\n",
    "- 2 states, s1 and s2\n",
    "- 2 actions, a1 and a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(i, j, k, K, n, t, v):\n",
    "    first = \"i: {}\\tj: {}\\tn: {}\\tT(k,j,n): {}\\tV(k): {}\".format(i, j, n, t, v)\n",
    "    others = \"T(k,j,n): {}\\tV(k): {}\".format(t, v)\n",
    "    if(k == 0):\n",
    "        print(first, end=\"\")\n",
    "    else:\n",
    "        print(others, end=\"\")\n",
    "    if(k != K):\n",
    "        print(\" +\\t\", end=\"\")\n",
    "    else:\n",
    "        print(\"\")\n",
    "\n",
    "def value_iteration(states, actions, T, rewards, gamma, beta, values=[], verbose=False):\n",
    "    \"\"\"\n",
    "        @brief: implements Bellman's equation to assign the max expected state values\n",
    "        \n",
    "        @input:\n",
    "            states: a list of states (length is j), type should be string if verbose=True i.e. [\"s1\", \"s2\", \"living room\" ... \"etc\"]\n",
    "            actions: a list of actions (length is n), type should be string if verbose=True i.e. [\"a1\", \"a2\", \"take picture\" ... \"etc\"]\n",
    "            T: a jxjxn matrix of transition probabilities P(Sj | Si, An) for all Sj, Si, and An, j=i is valid (self transitions)\n",
    "            rewards: an array of length j specifying the reward for each state. The reward value never changes.\n",
    "            gamma: the discount factor, i.e. how much do we care about future rewards\n",
    "            beta: the stopping criteria, i.e. minimum amount of improvement between iterations before stopping\n",
    "            values: [optional] current values of the states, set to the states reward value if not supplied\n",
    "            verbose: [optional] set to false \n",
    "        \n",
    "        @output:\n",
    "            values: an array of state values where V(S(i)) = V[i]\n",
    "            policy: a dictionary mapping states as keys to the best action as values, i.e. policy[\"some state\"] -> \"some action\"\n",
    "    \"\"\"\n",
    "    if(len(values) == 0):\n",
    "        values = rewards[:]\n",
    "    old_values = np.ones(len(rewards))*-999\n",
    "    #stopping_criteria = .005\n",
    "    policy = dict.fromkeys(states, \"\")\n",
    "    i = 0\n",
    "    while(abs(sum(values) - sum(old_values)) > beta):\n",
    "        old_values = values[:]\n",
    "        for j in range(0, len(states)): # all states in S\n",
    "            vals = np.zeros(len(actions))\n",
    "            for n in range(0, len(actions)): # valid actions in Sj\n",
    "                assert vals[n] == 0\n",
    "                for k in range(0, len(states)): # reachabe states from Sj\n",
    "                    vals[n] = vals[n] + T[k][j][n]*values[k]\n",
    "                    if(verbose):\n",
    "                        debug(i, j, k, len(states)-1, n, T[k][j][n], values[k])\n",
    "            values[j] = rewards[j] + gamma * np.amax(vals)\n",
    "            policy[states[j]] = actions[np.argmax(vals)]\n",
    "            if(verbose):\n",
    "                print(\"Vals: {}\".format(vals))\n",
    "                print(\"V({0}) = R({0}) + gamma*max({1})\".format(j, vals))\n",
    "                print(\"V({0}) = {1} + {2}*{3}\".format(j, rewards[j], gamma, np.amax(vals)))\n",
    "                print(\"V(\" + str(j) + \"): \" + str(values[j]))\n",
    "        i = i + 1\n",
    "    print(\"Stopping criteria met. state values have been permanently assigned.\")\n",
    "    print(\"V(s1) = {:.2f}\\tV(s2) = {:.2f}\".format(values[0], values[1]))\n",
    "    print(\"R(s1) = {:.2f}\\tR(s2) = {:.2f}\".format(rewards[0], rewards[1]))\n",
    "    print(\"Optimal policy: \")\n",
    "    for key, value in policy.items():\n",
    "        print(\"in state (\" + key + \") take action (\" + value+ \")\")\n",
    "    return values, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping criteria met. state values have been permanently assigned.\n",
      "V(s1) = 4.40\tV(s2) = 1.20\n",
      "R(s1) = 3.00\tR(s2) = -1.00\n",
      "Optimal policy: \n",
      "in state (s1) take action (a2)\n",
      "in state (s2) take action (a1)\n",
      "[4.399061441421509, 1.1995307207107544]\n",
      "{'s1': 'a2', 's2': 'a1'}\n"
     ]
    }
   ],
   "source": [
    "states = [\"s1\", \"s2\"]\n",
    "actions = [\"a1\", \"a2\"]\n",
    "rewards = [3, -1]\n",
    "\n",
    "# initialize the values\n",
    "# possible choices are random, zeros, or set to reward value\n",
    "values = rewards[:]\n",
    "\n",
    "# T is a jxjxn matrix of transition probabilities P(Sj | Si, An) for all Sj, Si, and An\n",
    "# P(s1 | s1, a1) = 0.0\n",
    "# P(s1 | s1, a2) = 0.5 \n",
    "# .... \n",
    "# P(s2 | s2, a2) = 1.0\n",
    "# This information must be given (or learned, but that is a different problem)\n",
    "T = [[[0, .5], [1.0, 0]], [[1.0, .5], [0, 1.0]]]\n",
    "\n",
    "# the weight factor for how much we care about future rewards\n",
    "gamma = .5\n",
    "\n",
    "# the stopping criteria, i.e. if improvement is less than this value then stop\n",
    "beta = .005\n",
    "values, policy = value_iteration(states, actions, T, rewards[:], gamma, beta, values=rewards[:], verbose=False)\n",
    "print(values)\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'nRows': 3, 'nCols': 4, 'stateObstacles': [5], 'stateTerminals': [10, 11], 'nStates': 12, 'nActions': 4, 'rewards': array([-0.04, -0.04, -0.04, -0.04,  0.  , -0.04, -0.04, -0.04, -0.04,\n",
      "        1.  , -1.  , -0.04]), 'states': ['s1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12'], 'actions': ['up', 'down', 'left', 'right'], 'values': array([-0.04, -0.04, -0.04, -0.04,  0.  , -0.04, -0.04, -0.04, -0.04,\n",
      "        1.  , -1.  , -0.04])}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04 -0.04 -0.04 -0.04  0.   -0.04 -0.04 -0.04 -0.04  1.   -1.   -0.04]\n",
      "[-0.04 -0.04 -0.04 -0.04  0.   -0.04 -0.04 -0.04 -0.04  1.   -1.   -0.04]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from World import World\n",
    "world = World()\n",
    "print(vars(world))\n",
    "world.plot()\n",
    "T = construct_T(world, p=.8, step=-.04)\n",
    "print(world.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_T(world):\n",
    "    T = np.zeros((self.nStates, self.nStates, self.nActions))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_p(world, p=0.8, step=-0.04):\n",
    "    nstates = world.get_nstates()\n",
    "    nrows = world.get_nrows()\n",
    "    obsacle_index = world.get_stateobstacles()\n",
    "    terminal_index = world.get_stateterminals()\n",
    "    bad_index = obsacle_index + terminal_index\n",
    "    rewards = np.array([step] * 4 + [0] + [step] * 4 + [1, -1] + [step])\n",
    "    actions = [\"N\", \"S\", \"E\", \"W\"]\n",
    "    transition_models = {}\n",
    "    for action in actions:\n",
    "        transition_model = np.zeros((nstates, nstates))\n",
    "        for i in range(1, nstates + 1):\n",
    "            if i not in bad_index:\n",
    "                if action == \"N\":\n",
    "                    if i + nrows <= nstates and (i + nrows) not in obsacle_index:\n",
    "                        transition_model[i - 1][i + nrows - 1] += (1 - p) / 2\n",
    "                    else:\n",
    "                        transition_model[i - 1][i - 1] += (1 - p) / 2\n",
    "                    if 0 < i - nrows <= nstates and (i - nrows) not in obsacle_index:\n",
    "                        transition_model[i - 1][i - nrows - 1] += (1 - p) / 2\n",
    "                    else:\n",
    "                        transition_model[i - 1][i - 1] += (1 - p) / 2\n",
    "                    if (i - 1) % nrows > 0 and (i - 1) not in obsacle_index:\n",
    "                        transition_model[i - 1][i - 1 - 1] += p\n",
    "                    else:\n",
    "                        transition_model[i - 1][i - 1] += p\n",
    "                if action == \"S\":\n",
    "                    if i + nrows <= nstates and (i + nrows) not in obsacle_index:\n",
    "                        transition_model[i - 1][i + nrows - 1] += (1 - p) / 2\n",
    "                    else:\n",
    "                        transition_model[i - 1][i - 1] += (1 - p) / 2\n",
    "                    if 0 < i - nrows <= nstates and (i - nrows) not in obsacle_index:\n",
    "                        transition_model[i - 1][i - nrows - 1] += (1 - p) / 2\n",
    "                    else:\n",
    "                        transition_model[i - 1][i - 1] += (1 - p) / 2\n",
    "                    if 0 < i % nrows and (i + 1) not in obsacle_index and (i + 1) <= nstates:\n",
    "                        transition_model[i - 1][i + 1 - 1] += p\n",
    "                    else:\n",
    "                        transition_model[i - 1][i - 1] += p\n",
    "                if action == \"E\":\n",
    "                    if i + nrows <= nstates and (i + nrows) not in obsacle_index:\n",
    "                        transition_model[i - 1][i + nrows - 1] += p\n",
    "                    else:\n",
    "                        transition_model[i - 1][i - 1] += p\n",
    "                    if 0 < i % nrows and (i + 1) not in obsacle_index and (i + 1) <= nstates:\n",
    "                        transition_model[i - 1][i + 1 - 1] += (1 - p) / 2\n",
    "                    else:\n",
    "                        transition_model[i - 1][i - 1] += (1 - p) / 2\n",
    "                    if (i - 1) % nrows > 0 and (i - 1) not in obsacle_index:\n",
    "                        transition_model[i - 1][i - 1 - 1] += (1 - p) / 2\n",
    "                    else:\n",
    "                        transition_model[i - 1][i - 1] += (1 - p) / 2\n",
    "                if action == \"W\":\n",
    "                    if 0 < i - nrows <= nstates and (i - nrows) not in obsacle_index:\n",
    "                        transition_model[i - 1][i - nrows - 1] += p\n",
    "                    else:\n",
    "                        transition_model[i - 1][i - 1] += p\n",
    "                    if 0 < i % nrows and (i + 1) not in obsacle_index and (i + 1) <= nstates:\n",
    "                        transition_model[i - 1][i + 1 - 1] += (1 - p) / 2\n",
    "                    else:\n",
    "                        transition_model[i - 1][i - 1] += (1 - p) / 2\n",
    "                    if (i - 1) % nrows > 0 and (i - 1) not in obsacle_index:\n",
    "                        transition_model[i - 1][i - 1 - 1] += (1 - p) / 2\n",
    "                    else:\n",
    "                        transition_model[i - 1][i - 1] += (1 - p) / 2\n",
    "            elif i in terminal_index:\n",
    "                transition_model[i - 1][i - 1] = 1\n",
    "        transition_models[action] = pd.DataFrame(transition_model, index=range(1, nstates + 1), columns=range(1, nstates + 1))\n",
    "\n",
    "    return transition_models, rewards"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
